{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44a554e",
   "metadata": {},
   "source": [
    "https://chatgpt.com/c/68ced95a-f138-832e-8e05-6ecd6d5f0c1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np\n",
    "import supervision as sv\n",
    "from sports import MeasurementUnit, ViewTransformer\n",
    "from sports.basketball import CourtConfiguration, League\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 94x50 ft NBA court config (vertices known & ordered by the sports package)\n",
    "CONFIG = CourtConfiguration(league=League.NBA, measurement_unit=MeasurementUnit.FEET)\n",
    "print(CONFIG.vertices) \n",
    "\n",
    "# Example: use CONFIG.vertices as source and target (for demonstration)\n",
    "source = np.array(CONFIG.vertices, dtype=np.float32)\n",
    "target = np.array(CONFIG.vertices, dtype=np.float32)  # Replace with your actual target points\n",
    "\n",
    "VT = ViewTransformer(source, target)\n",
    "print(dir(VT))  # Lists all attributes and methods\n",
    "print(vars(VT)) # Shows the object's __dict__ (attributes only, if available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf9ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# https://chatgpt.com/c/68ced95a-f138-832e-8e05-6ecd6d5f0c1d\n",
    "\n",
    "# %%\n",
    "# !gdown --folder https://drive.google.com/drive/folders/1eDJYqQ77Fytz15tKGdJCMeYSgmoQ-2-H\n",
    "# !gdown --folder https://drive.google.com/drive/folders/1RBjpI5Xleb58lujeusxH0W5zYMMA4ytO\n",
    "\n",
    "# %%\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from collections import deque\n",
    "from typing import Union, Sequence, Optional, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from inference import get_model\n",
    "# from google.colab import userdata\n",
    "from sports import MeasurementUnit, ViewTransformer\n",
    "from sports.basketball import (\n",
    "    CourtConfiguration,\n",
    "    League,\n",
    "    draw_court,\n",
    "    draw_made_and_miss_on_court,\n",
    "    ShotEventTracker,\n",
    "    ShotEvent,  # imported but not used; kept for parity with original\n",
    "    ShotType,   # imported but not used; kept for parity with original\n",
    ")\n",
    "\n",
    "# %%\n",
    "# 94x50 ft NBA court config (vertices known & ordered by the sports package)\n",
    "CONFIG = CourtConfiguration(league=League.NBA, measurement_unit=MeasurementUnit.FEET)\n",
    "print(CONFIG.vertices)\n",
    "\n",
    "# Example: use CONFIG.vertices as source and target (for demonstration)\n",
    "source = np.array(CONFIG.vertices, dtype=np.float32)\n",
    "target = np.array(CONFIG.vertices, dtype=np.float32)  # Replace with your actual target points\n",
    "\n",
    "VT = ViewTransformer(source, target)\n",
    "print(dir(VT))   # Lists all attributes and methods\n",
    "print(vars(VT))  # Shows the object's __dict__ (attributes only, if available)\n",
    "\n",
    "# %%\n",
    "# config.py\n",
    "from pathlib import Path as _Path  # (alias to avoid shadowing above)\n",
    "import supervision as _sv\n",
    "from sports import MeasurementUnit as _MeasurementUnit, ViewTransformer as _ViewTransformer\n",
    "from sports.basketball import CourtConfiguration as _CourtConfiguration, League as _League\n",
    "from inference import get_model as _get_model  # assumes available\n",
    "\n",
    "src = _Path(\"api/src/cv/src\")\n",
    "court_image_dir = _Path(\"api/src/cv/data/images/court_detection/basketball-court-detection-2-1\")\n",
    "coordinates_dir = _Path(\"api/src/cv/data/coordinates\")\n",
    "video_dir = _Path(\"api/src/cv/data/videos\")\n",
    "boston_ex_video_path = video_dir / \"boston-celtics-new-york-knicks-game-1\"\n",
    "\n",
    "SOURCE_VIDEO_PATH = _Path(\n",
    "    \"/workspace/api/src/cv/data/video/boston-celtics-new-york-knicks-game-1/\"\n",
    "    \"boston-celtics-new-york-knicks-game-1-q1-03.16-03.11.mp4\"\n",
    ")\n",
    "\n",
    "api_key = \"htpcxp3XQh7SsgMfjJns\"\n",
    "\n",
    "PLAYER_DETECTION_MODEL_ID = \"basketball-player-detection-3-ycjdo/4\"\n",
    "PLAYER_DETECTION_MODEL = _get_model(model_id=PLAYER_DETECTION_MODEL_ID, api_key=api_key)\n",
    "\n",
    "COURT_DETECTION_MODEL_ID = \"basketball-court-detection-2/14\"\n",
    "COURT_DETECTION_MODEL = _get_model(model_id=COURT_DETECTION_MODEL_ID, api_key=api_key)\n",
    "\n",
    "# 94x50 ft NBA court config (vertices known & ordered by the sports package)\n",
    "CONFIG = _CourtConfiguration(league=_League.NBA, measurement_unit=_MeasurementUnit.FEET)\n",
    "print(CONFIG.vertices)\n",
    "\n",
    "COLOR = sv.ColorPalette.from_hex([\n",
    "    \"#ffff00\", \"#ff9b00\", \"#ff66ff\", \"#3399ff\", \"#ff66b2\", \"#ff8080\",\n",
    "    \"#b266ff\", \"#9999ff\", \"#66ffff\", \"#33ff99\", \"#66ff66\", \"#99ff00\"\n",
    "])\n",
    "MAGENTA_COLOR = sv.Color.from_hex(\"#FF1493\")\n",
    "CYAN_COLOR = sv.Color.from_hex(\"#00BFFF\")\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "IOU_THRESHOLD = 0.7\n",
    "BALL_IN_BASKET_CLASS_ID = 1\n",
    "JUMP_SHOT_CLASS_ID = 5\n",
    "LAYUP_DUNK_CLASS_ID = 6\n",
    "\n",
    "# %%\n",
    "# from roboflow import Roboflow\n",
    "# rf = Roboflow(api_key=api_key)\n",
    "# project = rf.workspace(\"basketball-formations\").project(\"basketball-court-detection-2-mlopt\")\n",
    "# version = project.version(1)\n",
    "# dataset = version.download(\"yolov8\")\n",
    "\n",
    "# %% [markdown]\n",
    "# # ball, number, player, referee and basket detection\n",
    "\n",
    "# %%\n",
    "print(f\"current working directory: {os.getcwd()}\")\n",
    "# check on SOURCE_VIDEO_PATH\n",
    "print(f\"SOURCE_VIDEO_PATH: {SOURCE_VIDEO_PATH}\")\n",
    "print(f\"COURT_DETECTION_MODEL: {COURT_DETECTION_MODEL}\")\n",
    "\n",
    "# test pull in the video\n",
    "cap = cv2.VideoCapture(str(SOURCE_VIDEO_PATH))\n",
    "ret, frame = cap.read()\n",
    "print(f\"frame (first read): {type(frame)}, shape={None if frame is None else frame.shape}\")\n",
    "cap.release()\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(color=COLOR, thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(color=COLOR, text_color=sv.Color.BLACK)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.35)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "sv.plot_image(annotated_frame)\n",
    "\n",
    "# %% [markdown]\n",
    "# detect jump-shots\n",
    "\n",
    "# %%\n",
    "box_annotator = sv.BoxAnnotator(color=COLOR, thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(color=COLOR, text_color=sv.Color.BLACK)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.35)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "detections = detections[detections.class_id == 5]\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "sv.plot_image(annotated_frame)\n",
    "\n",
    "# %%\n",
    "COLOR = sv.Color.from_hex(\"#007A33\")\n",
    "TEXT_COLOR = sv.Color.WHITE\n",
    "\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=COLOR, base=25, height=21, color_lookup=sv.ColorLookup.INDEX\n",
    ")\n",
    "text_annotator = sv.RichLabelAnnotator(\n",
    "    # font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
    "    font_size=60,\n",
    "    color=COLOR,\n",
    "    text_color=TEXT_COLOR,\n",
    "    # text_offset=(0, -30),\n",
    "    color_lookup=sv.ColorLookup.INDEX,\n",
    "    text_position=sv.Position.TOP_CENTER,\n",
    ")\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.35)[0]\n",
    "detections = sv.Detections.from_inference(result)\n",
    "detections = detections[detections.class_id == 5]\n",
    "\n",
    "xy = detections.get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "\n",
    "# small hack to convert points into detections\n",
    "xyxy = sv.pad_boxes(np.hstack((xy, xy)), px=1, py=1)\n",
    "detections = sv.Detections(xyxy=xyxy)\n",
    "labels = [\"here\"] * len(detections)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = triangle_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "annotated_frame = text_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "sv.plot_image(annotated_frame)\n",
    "\n",
    "# %% [markdown]\n",
    "# detect basketball court keypoints\n",
    "\n",
    "# %%\n",
    "vertex_annotator = sv.VertexAnnotator(color=MAGENTA_COLOR, radius=8)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "result = COURT_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "key_points = sv.KeyPoints.from_inference(result)\n",
    "\n",
    "annotated_frame = frame.copy()\n",
    "annotated_frame = vertex_annotator.annotate(scene=annotated_frame, key_points=key_points)\n",
    "sv.plot_image(annotated_frame)\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "\n",
    "def filter_keypoints_by_confidence(\n",
    "    key_points: sv.KeyPoints, min_conf: float, object_index: int = 0\n",
    ") -> sv.KeyPoints:\n",
    "    \"\"\"\n",
    "    Filter keypoints by confidence for a SINGLE object inside a Supervision KeyPoints.\n",
    "    Returns a NEW KeyPoints with shape (1, k, 2) / (1, k); never mutates the input.\n",
    "\n",
    "    - key_points.xy: expected (n, m, 2)\n",
    "    - key_points.confidence: expected (n, m)\n",
    "    - key_points.class_id: (n,) or None\n",
    "    - key_points.data: dict-like (must NOT be None in your supervision version)\n",
    "\n",
    "    Raises with explicit messages if shapes/fields are unexpected.\n",
    "    \"\"\"\n",
    "    if key_points is None:\n",
    "        raise ValueError(\"filter_keypoints_by_confidence: key_points is None.\")\n",
    "    if key_points.confidence is None:\n",
    "        raise ValueError(\n",
    "            \"filter_keypoints_by_confidence: confidences are None; model did not return per-keypoint confidences.\"\n",
    "        )\n",
    "\n",
    "    xy = key_points.xy\n",
    "    conf = key_points.confidence\n",
    "\n",
    "    if xy.ndim != 3 or xy.shape[-1] != 2:\n",
    "        raise ValueError(f\"Expected xy shape (n, m, 2); got {xy.shape}.\")\n",
    "    if conf.ndim != 2:\n",
    "        raise ValueError(f\"Expected confidence shape (n, m); got {conf.shape}.\")\n",
    "\n",
    "    n, m, _ = xy.shape\n",
    "    if conf.shape != (n, m):\n",
    "        raise ValueError(f\"xy/conf shape mismatch: xy {xy.shape}, conf {conf.shape}.\")\n",
    "    if not (0 <= object_index < n):\n",
    "        raise IndexError(f\"object_index {object_index} out of range for n={n}.\")\n",
    "\n",
    "    # Construct per-object mask along the m dimension\n",
    "    obj_mask = conf[object_index] > float(min_conf)\n",
    "    kept = int(obj_mask.sum())\n",
    "    print(f\"[DEBUG] objects: {n}, keypoints per obj: {m}, threshold: {min_conf}, kept(obj={object_index}): {kept}\")\n",
    "\n",
    "    # Slice to new arrays with shape (1, k, 2) and (1, k)\n",
    "    new_xy = xy[object_index:object_index + 1, obj_mask, :]  # (1, k, 2)\n",
    "    new_conf = conf[object_index:object_index + 1, obj_mask]  # (1, k)\n",
    "\n",
    "    # Carry over class_id for the single object (shape (1,)) or None\n",
    "    new_cls = None if key_points.class_id is None else key_points.class_id[object_index:object_index + 1]\n",
    "\n",
    "    # Propagate original data if available; else use an empty dict.\n",
    "    original_data = getattr(key_points, \"data\", None)\n",
    "    new_data = original_data if isinstance(original_data, dict) else {}\n",
    "\n",
    "    # If nothing passes, return an empty but well-formed KeyPoints\n",
    "    if kept == 0:\n",
    "        empty_xy = np.empty((1, 0, 2), dtype=new_xy.dtype)\n",
    "        empty_conf = np.empty((1, 0), dtype=new_conf.dtype)\n",
    "        return sv.KeyPoints(xy=empty_xy, confidence=empty_conf, class_id=new_cls, data=new_data)\n",
    "\n",
    "    return sv.KeyPoints(xy=new_xy, confidence=new_conf, class_id=new_cls, data=new_data)\n",
    "\n",
    "\n",
    "def sort_keypoints_by_class_id(key_points: sv.KeyPoints) -> sv.KeyPoints:\n",
    "    \"\"\"Return KeyPoints sorted by class_id if available; otherwise return as-is.\"\"\"\n",
    "    if key_points.class_id is None or len(key_points.class_id) == 0:\n",
    "        return key_points\n",
    "    idx = np.argsort(key_points.class_id)\n",
    "    return key_points[idx]\n",
    "\n",
    "\n",
    "def debug_dump_keypoints(key_points: sv.KeyPoints, limit: int = 10):\n",
    "    \"\"\"Print a small table of confidences and (x,y) for up to limit keypoints of each object.\"\"\"\n",
    "    xy = key_points.xy\n",
    "    conf = key_points.confidence\n",
    "    n, m, _ = xy.shape\n",
    "    print(f\"[DEBUG] dump: n={n}, m={m}, limit={limit}\")\n",
    "    for i in range(n):\n",
    "        count = min(limit, m)\n",
    "        print(f\" [obj {i}] first {count} keypoints:\")\n",
    "        for j in range(count):\n",
    "            cj = None if conf is None else float(conf[i, j])\n",
    "            x, y = float(xy[i, j, 0]), float(xy[i, j, 1])\n",
    "            print(f\"  - idx={j:02d} | conf={cj:.4f} | (x,y)=({x:.1f},{y:.1f})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MAGENTA_COLOR = sv.Color(r=255, g=0, b=255)\n",
    "    vertex_annotator = sv.VertexAnnotator(color=MAGENTA_COLOR, radius=8)\n",
    "\n",
    "    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "    frame = next(frame_generator)\n",
    "\n",
    "    result = COURT_DETECTION_MODEL.infer(frame, confidence=0.3)[0]\n",
    "    print(f\"result: {result}\")\n",
    "\n",
    "    key_points = sv.KeyPoints.from_inference(result)\n",
    "    print(\"[DEBUG] xy shape:\", key_points.xy.shape)\n",
    "    print(\"[DEBUG] conf shape:\", key_points.confidence.shape)\n",
    "    print(\"[DEBUG] class_id shape:\", None if key_points.class_id is None else key_points.class_id.shape)\n",
    "\n",
    "    # NEW: filter within the single detection (object_index=0)\n",
    "    key_points = filter_keypoints_by_confidence(key_points, min_conf=0.5, object_index=0)\n",
    "\n",
    "    # Optional peek\n",
    "    debug_dump_keypoints(key_points, limit=8)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = vertex_annotator.annotate(scene=annotated_frame, key_points=key_points)\n",
    "    sv.plot_image(annotated_frame)\n",
    "\n",
    "# %% [markdown]\n",
    "# mark jump-shot location\n",
    "\n",
    "# %%\n",
    "CONFIG = CourtConfiguration(league=League.NBA, measurement_unit=MeasurementUnit.FEET)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH, start=65, iterative_seek=True)\n",
    "frame = next(frame_generator)\n",
    "\n",
    "# detect court keypoints\n",
    "court_result = COURT_DETECTION_MODEL.infer(frame, confidence=0.35)[0]\n",
    "key_points = sv.KeyPoints.from_inference(court_result)\n",
    "\n",
    "keypoint_mask = key_points.confidence[0] > 0.5\n",
    "have_enough_points = np.count_nonzero(keypoint_mask) >= 4\n",
    "\n",
    "if have_enough_points:\n",
    "    court_vertices_masked = np.array(CONFIG.vertices)[keypoint_mask]          # (k, 2)\n",
    "    detected_on_image = key_points.xy[0, keypoint_mask]                       # (k, 2)\n",
    "\n",
    "    image_to_court = ViewTransformer(\n",
    "        source=detected_on_image,\n",
    "        target=court_vertices_masked,\n",
    "    )\n",
    "\n",
    "    # detect jump-shot\n",
    "    result = PLAYER_DETECTION_MODEL.infer(frame, confidence=0.35)[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "    image_xy = detections[detections.class_id == 5].get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "\n",
    "    if len(image_xy) > 0:\n",
    "        court_xy = image_to_court.transform_points(points=image_xy)\n",
    "        court = draw_made_and_miss_on_court(\n",
    "            config=CONFIG,\n",
    "            made_xy=court_xy,\n",
    "            made_size=25,\n",
    "            made_color=sv.Color.from_hex(\"#007A33\"),\n",
    "            made_thickness=6,\n",
    "            line_thickness=4,\n",
    "        )\n",
    "        sv.plot_image(court)\n",
    "\n",
    "# %% [markdown]\n",
    "# detect shot events\n",
    "\n",
    "# %%\n",
    "box_annotator = sv.BoxAnnotator(color=COLOR, thickness=2)\n",
    "label_annotator = sv.LabelAnnotator(color=COLOR, text_color=sv.Color.BLACK)\n",
    "\n",
    "frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)\n",
    "video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)\n",
    "\n",
    "shot_event_tracker = ShotEventTracker(\n",
    "    reset_time_frames=int(video_info.fps * 1.7),\n",
    "    minimum_frames_between_starts=int(video_info.fps * 0.5),\n",
    "    cooldown_frames_after_made=int(video_info.fps * 0.5),\n",
    ")\n",
    "\n",
    "for frame_index, frame in enumerate(frame_generator):\n",
    "    result = PLAYER_DETECTION_MODEL.infer(\n",
    "        frame, confidence=CONFIDENCE_THRESHOLD, iou_threshold=IOU_THRESHOLD\n",
    "    )[0]\n",
    "    detections = sv.Detections.from_inference(result)\n",
    "\n",
    "    has_jump_shot = len(detections[detections.class_id == JUMP_SHOT_CLASS_ID]) > 0\n",
    "    has_layup_dunk = len(detections[detections.class_id == LAYUP_DUNK_CLASS_ID]) > 0\n",
    "    has_ball_in_basket = len(detections[detections.class_id == BALL_IN_BASKET_CLASS_ID]) > 0\n",
    "\n",
    "    events = shot_event_tracker.update(\n",
    "        frame_index=frame_index,\n",
    "        has_jump_shot=has_jump_shot,\n",
    "        has_layup_dunk=has_layup_dunk,\n",
    "        has_ball_in_basket=has_ball_in_basket,\n",
    "    )\n",
    "    if events:\n",
    "        print(events)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    sv.plot_image(annotated_frame)\n",
    "\n",
    "# %% [markdown]\n",
    "# end-to-end multi-video processing\n",
    "\n",
    "# %%\n",
    "# Ensure HOME is defined (used by font paths / source dir below)\n",
    "HOME = str(Path.home())\n",
    "\n",
    "CONFIG = CourtConfiguration(league=League.NBA, measurement_unit=MeasurementUnit.FEET)\n",
    "COLOR = sv.ColorPalette.from_hex([\"#007A33\", \"#006BB6\"])\n",
    "TEXT_COLOR = sv.Color.WHITE\n",
    "\n",
    "triangle_annotator = sv.TriangleAnnotator(\n",
    "    color=COLOR, base=25, height=21, color_lookup=sv.ColorLookup.CLASS\n",
    ")\n",
    "text_annotator = sv.RichLabelAnnotator(\n",
    "    # font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
    "    font_size=60,\n",
    "    color=COLOR,\n",
    "    text_color=TEXT_COLOR,\n",
    "    # text_offset=(0, -30),\n",
    "    color_lookup=sv.ColorLookup.CLASS,\n",
    "    text_position=sv.Position.TOP_CENTER,\n",
    ")\n",
    "\n",
    "triangle_annotator_missed = sv.TriangleAnnotator(\n",
    "    color=sv.Color.from_hex(\"#850101\"), base=25, height=21, color_lookup=sv.ColorLookup.CLASS\n",
    ")\n",
    "text_annotator_missed = sv.RichLabelAnnotator(\n",
    "    font_path=f\"{HOME}/fonts/Staatliches-Regular.ttf\",\n",
    "    font_size=60,\n",
    "    color=sv.Color.from_hex(\"#850101\"),\n",
    "    text_color=TEXT_COLOR,\n",
    "    # text_offset=(0, -30),\n",
    "    color_lookup=sv.ColorLookup.CLASS,\n",
    "    text_position=sv.Position.TOP_CENTER,\n",
    ")\n",
    "\n",
    "class KeyPointsSmoother:\n",
    "    def __init__(self, length: int):\n",
    "        self.length = length\n",
    "        self.buffer = deque(maxlen=length)\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        xy: np.ndarray,\n",
    "        confidence: Optional[np.ndarray] = None,\n",
    "        conf_threshold: float = 0.0,\n",
    "    ) -> np.ndarray:\n",
    "        assert xy.ndim == 3 and xy.shape[0] == 1\n",
    "        xy_f = xy.astype(np.float32, copy=True)\n",
    "\n",
    "        if confidence is not None:\n",
    "            assert confidence.shape[:2] == xy.shape[:2]\n",
    "            mask = (confidence >= conf_threshold)[..., None]\n",
    "            xy_f = np.where(mask, xy_f, np.nan)\n",
    "\n",
    "        self.buffer.append(xy_f)\n",
    "        stacked = np.stack(self.buffer, axis=0)\n",
    "\n",
    "        if np.isnan(stacked).any():\n",
    "            mean_xy = np.nanmean(stacked, axis=0)\n",
    "        else:\n",
    "            mean_xy = stacked.mean(axis=0)\n",
    "\n",
    "        return mean_xy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Shot:\n",
    "    x: float\n",
    "    y: float\n",
    "    distance: float\n",
    "    result: bool\n",
    "    team: int\n",
    "\n",
    "\n",
    "def euclidean_distance(\n",
    "    start_point: Union[Sequence[float], np.ndarray],\n",
    "    end_point: Union[Sequence[float], np.ndarray],\n",
    ") -> float:\n",
    "    start_point_array = np.asarray(start_point, dtype=float)\n",
    "    end_point_array = np.asarray(end_point, dtype=float)\n",
    "    if start_point_array.shape != (2,) or end_point_array.shape != (2,):\n",
    "        raise ValueError(\"Both points must have shape (2,).\")\n",
    "    return float(np.linalg.norm(end_point_array - start_point_array))\n",
    "\n",
    "\n",
    "def extract_made(shots: List[Shot]):\n",
    "    return [shot for shot in shots if shot.result]\n",
    "\n",
    "\n",
    "def extract_xy(shots: List[Shot]) -> np.ndarray:\n",
    "    return np.array([[shot.x, shot.y] for shot in shots], dtype=float)\n",
    "\n",
    "\n",
    "def extract_class_id(shots: List[Shot]) -> np.ndarray:\n",
    "    return np.array([shot.team for shot in shots], dtype=int)\n",
    "\n",
    "\n",
    "def extract_label(shots: List[Shot]) -> np.ndarray:\n",
    "    return np.array([f\"{shot.distance:.2f} ft\" for shot in shots], dtype=str)\n",
    "\n",
    "\n",
    "SOURCE_VIDEO_DIR = Path(HOME) / \"boston-celtics-new-york-knicks-game-1\"\n",
    "SOURCE_VIDEO_NAMES = [\n",
    "    \"boston-celtics-new-york-knicks-game-1-q1-03.16-03.11.mp4\",\n",
    "    \"boston-celtics-new-york-knicks-game-1-q1-04.44-04.39.mp4\",\n",
    "    \"boston-celtics-new-york-knicks-game-1-q1-06.00-05.54.mp4\",\n",
    "    \"boston-celtics-new-york-knicks-game-1-q1-07.41-07.34.mp4\",\n",
    "]\n",
    "SOURCE_VIDEO_PATHS = [SOURCE_VIDEO_DIR / video_name for video_name in SOURCE_VIDEO_NAMES]\n",
    "\n",
    "KEYPOINT_CONFIDENCE_THRESHOLD = 0.5\n",
    "DETECTION_CONFIDENCE = 0.3\n",
    "CONFIDENCE_THRESHOLD = 0.3\n",
    "IOU_THRESHOLD = 0.7\n",
    "BALL_IN_BASKET_CLASS_ID = 1\n",
    "JUMP_SHOT_CLASS_ID = 5\n",
    "LAYUP_DUNK_CLASS_ID = 6\n",
    "BALL_IN_BASKET_MIN_CONSECUTIVE_FRAMES = 2\n",
    "JUMP_SHOT_MIN_CONSECUTIVE_FRAMES = 3\n",
    "LAYUP_DUNK_MIN_CONSECUTIVE_FRAMES = 3\n",
    "\n",
    "shots: List[Shot] = []\n",
    "\n",
    "COURT_SCALE = 20\n",
    "COURT_PADDING = 50\n",
    "COURT_LINE_THICKNESS = 4\n",
    "\n",
    "court_base = draw_court(\n",
    "    config=CONFIG,\n",
    "    scale=COURT_SCALE,\n",
    "    padding=COURT_PADDING,\n",
    "    line_thickness=COURT_LINE_THICKNESS,\n",
    ")\n",
    "court_h, court_w = court_base.shape[:2]\n",
    "\n",
    "for video_path in tqdm(SOURCE_VIDEO_PATHS, desc=\"Videos\", position=0):\n",
    "    target_video_path = video_path.parent / f\"{video_path.stem}-markers{video_path.suffix}\"\n",
    "    target_video_compressed_path = (\n",
    "        target_video_path.parent / f\"{target_video_path.stem}-compressed{target_video_path.suffix}\"\n",
    "    )\n",
    "    target_court_video_path = video_path.parent / f\"{video_path.stem}-court{video_path.suffix}\"\n",
    "    target_court_video_compressed_path = (\n",
    "        target_court_video_path.parent\n",
    "        / f\"{target_court_video_path.stem}-compressed{target_court_video_path.suffix}\"\n",
    "    )\n",
    "\n",
    "    video_info = sv.VideoInfo.from_video_path(str(video_path))\n",
    "    total_frames = getattr(video_info, \"total_frames\", getattr(video_info, \"frame_count\", None))\n",
    "    frame_generator = sv.get_video_frames_generator(str(video_path))\n",
    "\n",
    "    court_video_info = sv.VideoInfo(\n",
    "        width=court_w, height=court_h, fps=video_info.fps, total_frames=total_frames\n",
    "    )\n",
    "\n",
    "    shot_event_tracker = ShotEventTracker(\n",
    "        reset_time_frames=int(video_info.fps * 1.7),\n",
    "        minimum_frames_between_starts=int(video_info.fps * 0.5),\n",
    "        cooldown_frames_after_made=int(video_info.fps * 0.5),\n",
    "    )\n",
    "    smoother = KeyPointsSmoother(length=3)\n",
    "    shot_in_progress_xy: Optional[np.ndarray] = None\n",
    "\n",
    "    with sv.VideoSink(str(target_video_path), video_info) as sink, \\\n",
    "         sv.VideoSink(str(target_court_video_path), court_video_info) as court_sink:\n",
    "\n",
    "        for frame_index, frame in tqdm(\n",
    "            enumerate(frame_generator),\n",
    "            total=int(total_frames) if total_frames else None,\n",
    "            desc=f\"Frames: {video_path.name}\",\n",
    "            position=1,\n",
    "            leave=False,\n",
    "        ):\n",
    "            # ================= Player detections and state ================\n",
    "            player_result = PLAYER_DETECTION_MODEL.infer(\n",
    "                frame, confidence=CONFIDENCE_THRESHOLD, iou_threshold=IOU_THRESHOLD\n",
    "            )[0]\n",
    "            player_detections = sv.Detections.from_inference(player_result)\n",
    "\n",
    "            has_jump_shot = len(player_detections[player_detections.class_id == JUMP_SHOT_CLASS_ID]) > 0\n",
    "            has_layup_dunk = len(player_detections[player_detections.class_id == LAYUP_DUNK_CLASS_ID]) > 0\n",
    "            has_ball_in_basket = len(player_detections[player_detections.class_id == BALL_IN_BASKET_CLASS_ID]) > 0\n",
    "\n",
    "            events = shot_event_tracker.update(\n",
    "                frame_index=frame_index,\n",
    "                has_jump_shot=has_jump_shot,\n",
    "                has_layup_dunk=has_layup_dunk,\n",
    "                has_ball_in_basket=has_ball_in_basket,\n",
    "            )\n",
    "\n",
    "            # ================= Court keypoints and transforms =============\n",
    "            court_result = COURT_DETECTION_MODEL.infer(frame, confidence=DETECTION_CONFIDENCE)[0]\n",
    "            key_points = sv.KeyPoints.from_inference(court_result)\n",
    "            key_points.xy = smoother.update(\n",
    "                xy=key_points.xy,\n",
    "                confidence=key_points.confidence,\n",
    "                conf_threshold=0.5,\n",
    "            )\n",
    "\n",
    "            key_mask = key_points.confidence[0] > KEYPOINT_CONFIDENCE_THRESHOLD\n",
    "            have_enough_points = np.count_nonzero(key_mask) >= 4\n",
    "\n",
    "            if have_enough_points:\n",
    "                court_vertices_masked = np.array(CONFIG.vertices)[key_mask]\n",
    "                detected_on_image = key_points.xy[0, key_mask]\n",
    "\n",
    "                image_to_court = ViewTransformer(\n",
    "                    source=detected_on_image,\n",
    "                    target=court_vertices_masked,\n",
    "                )\n",
    "                court_to_image = ViewTransformer(\n",
    "                    source=court_vertices_masked,\n",
    "                    target=detected_on_image,\n",
    "                )\n",
    "\n",
    "            # ================= Events and global shot list =================\n",
    "            if events:\n",
    "                start_events = [e for e in events if e[\"event\"] == \"START\"]\n",
    "                made_events = [e for e in events if e[\"event\"] == \"MADE\"]\n",
    "                missed_events = [e for e in events if e[\"event\"] == \"MISSED\"]\n",
    "\n",
    "                if start_events and have_enough_points:\n",
    "                    anchors_image = player_detections[\n",
    "                        (player_detections.class_id == JUMP_SHOT_CLASS_ID)\n",
    "                        | (player_detections.class_id == LAYUP_DUNK_CLASS_ID)\n",
    "                    ].get_anchors_coordinates(anchor=sv.Position.BOTTOM_CENTER)\n",
    "\n",
    "                    if len(anchors_image) > 0:\n",
    "                        anchors_court = image_to_court.transform_points(points=anchors_image)\n",
    "                        shot_in_progress_xy = anchors_court[0]\n",
    "\n",
    "                if made_events and shot_in_progress_xy is not None:\n",
    "                    shots.append(\n",
    "                        Shot(\n",
    "                            x=shot_in_progress_xy[0],\n",
    "                            y=shot_in_progress_xy[1],\n",
    "                            distance=euclidean_distance(\n",
    "                                start_point=shot_in_progress_xy,\n",
    "                                end_point=CONFIG.vertices[CONFIG.left_basket_index],\n",
    "                            ),\n",
    "                            result=True,\n",
    "                            team=0,\n",
    "                        )\n",
    "                    )\n",
    "                    shot_in_progress_xy = None\n",
    "\n",
    "                if missed_events and shot_in_progress_xy is not None:\n",
    "                    shots.append(\n",
    "                        Shot(\n",
    "                            x=shot_in_progress_xy[0],\n",
    "                            y=shot_in_progress_xy[1],\n",
    "                            distance=euclidean_distance(\n",
    "                                start_point=shot_in_progress_xy,\n",
    "                                end_point=CONFIG.vertices[CONFIG.left_basket_index],\n",
    "                            ),\n",
    "                            result=False,\n",
    "                            team=0,\n",
    "                        )\n",
    "                    )\n",
    "                    shot_in_progress_xy = None\n",
    "\n",
    "            # ================= Render broadcast overlay ===================\n",
    "            annotated = frame.copy()\n",
    "\n",
    "            if have_enough_points and len(shots) > 0:\n",
    "                made_shots = [s for s in shots if s.result is True]\n",
    "                missed_shots = [s for s in shots if s.result is False]\n",
    "\n",
    "                if len(made_shots) > 0:\n",
    "                    made_xy_court = extract_xy(shots=made_shots)\n",
    "                    made_xy_image = court_to_image.transform_points(points=made_xy_court)\n",
    "                    boxes_xyxy_made = sv.pad_boxes(np.hstack((made_xy_image, made_xy_image)), px=1, py=1)\n",
    "                    classes_made = extract_class_id(shots=made_shots)\n",
    "                    detections_made = sv.Detections(xyxy=boxes_xyxy_made, class_id=classes_made)\n",
    "                    labels_made = [f\"{int(shot.distance)} feet\" for shot in made_shots]\n",
    "\n",
    "                    annotated = triangle_annotator.annotate(scene=annotated, detections=detections_made)\n",
    "                    annotated = text_annotator.annotate(\n",
    "                        scene=annotated, detections=detections_made, labels=labels_made\n",
    "                    )\n",
    "\n",
    "                if len(missed_shots) > 0:\n",
    "                    missed_xy_court = extract_xy(shots=missed_shots)\n",
    "                    missed_xy_image = court_to_image.transform_points(points=missed_xy_court)\n",
    "                    boxes_xyxy_missed = sv.pad_boxes(np.hstack((missed_xy_image, missed_xy_image)), px=1, py=1)\n",
    "                    classes_missed = extract_class_id(shots=missed_shots)\n",
    "                    detections_missed = sv.Detections(xyxy=boxes_xyxy_missed, class_id=classes_missed)\n",
    "                    labels_missed = [\"missed\"] * len(missed_shots)\n",
    "\n",
    "                    annotated = triangle_annotator_missed.annotate(scene=annotated, detections=detections_missed)\n",
    "                    annotated = text_annotator_missed.annotate(\n",
    "                        scene=annotated, detections=detections_missed, labels=labels_missed\n",
    "                    )\n",
    "\n",
    "            # Write anno\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445944e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bball_homography_pipeline_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
